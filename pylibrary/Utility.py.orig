"""
Utils.py - general utility routines
- power spectrum
- elliptical filtering
- handling very long input lines for dictionaries
- general measurement routines for traces (mean, std, spikes, etc)

"declassed", 7/28/09 p. manis
Use as:
import Utility as Utils
then call Utils.xxxxx()

"""
# January, 2009
# Paul B. Manis, Ph.D.
# UNC Chapel Hill
# Department of Otolaryngology/Head and Neck Surgery
# Supported by NIH Grants DC000425-22 and DC004551-07 to PBM.
# Copyright Paul Manis, 2009
#
"""
    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <http://www.gnu.org/licenses/>.
"""

import sys, re, os
import numpy
import numpy.ma as ma
import scipy.fftpack as spFFT
import scipy.signal as spSignal

from random import sample

debugFlag = False

def setDebug(debug=False):
    if debug:
        debugFlag = True
    else:
        debugFlag = False


def pSpectrum(data=None, samplefreq=44100):
    npts = len(data)
# we should window the data here
    if npts == 0:
        print "? no data in pSpectrum"
        return
# pad to the nearest higher power of 2
    (a,b) = numpy.frexp(npts)
    if a <= 0.5:
        b = b = 1
    npad = 2**b -npts
    if debugFlag:
        print "npts: %d   npad: %d   npad+npts: %d" % (npts, npad, npad+npts)
    padw =  numpy.append(data, numpy.zeros(npad))
    npts = len(padw)
    sigfft = spFFT.fft(padw)
    nUniquePts = numpy.ceil((npts+1)/2.0)
    sigfft = sigfft[0:nUniquePts]
    spectrum = abs(sigfft)
    spectrum = spectrum / float(npts) # scale by the number of points so that
                       # the magnitude does not depend on the length
                       # of the signal or on its sampling frequency
    spectrum = spectrum**2  # square it to get the power
    spmax = numpy.amax(spectrum)
    spectrum = spectrum + 1e-12*spmax
    # multiply by two (see technical document for details)
    # odd nfft excludes Nyquist point
    if npts % 2 > 0: # we've got odd number of points fft
        spectrum[1:len(spectrum)] = spectrum[1:len(spectrum)] * 2
    else:
        spectrum[1:len(spectrum) -1] = spectrum[1:len(spectrum) - 1] * 2 # we've got even number of points fft
    freqAzero = numpy.arange(0, nUniquePts, 1.0) * (samplefreq / npts)
    return(spectrum, freqAzero)

# filter signal with elliptical filter
def SignalFilter(signal, LPF, HPF, samplefreq):
    if debugFlag:
        print "sfreq: %f LPF: %f HPF: %f" % (samplefreq, LPF, HPF)
    flpf = float(LPF)
    fhpf = float(HPF)
    sf = float(samplefreq)
    sf2 = sf/2
    wp = [fhpf/sf2, flpf/sf2]
    ws = [0.5*fhpf/sf2, 2*flpf/sf2]
    if debugFlag:
        print "signalfilter: samplef: %f  wp: %f, %f  ws: %f, %f lpf: %f  hpf: %f" % (
           sf, wp[0], wp[1], ws[0], ws[1], flpf, fhpf)
    filter_b,filter_a=spSignal.iirdesign(wp, ws,
            gpass=1.0,
            gstop=60.0,
            ftype="ellip")
    w=spSignal.lfilter(filter_b, filter_a, signal) # filter the incoming signal
    if debugFlag:
        print "sig: %f-%f w: %f-%f" % (numpy.amin(signal), numpy.amax(signal), numpy.amin(w), numpy.amax(w))
    return(w)

# filter signal with low-pass Bessel
def SignalFilter_LPFBessel(signal, LPF, samplefreq, NPole = 8, reduce = False):
    """ Low pass filter a signal, possibly reducing the number of points in the
        data array.
        signal: a numpya array of dim = 1, 2 or 3. The "last" dimension is filtered.
        LPF: low pass filter frequency, in Hz
        samplefreq: sampline frequency (points/second)
        NPole: number of poles in the filter.
        reduce: Flag that controls whether the resulting data is subsampled or not
    """
    if debugFlag:
        print "sfreq: %f LPF: %f HPF: %f" % (samplefreq, LPF)
    flpf = float(LPF)
    sf = float(samplefreq)
    wn = [flpf/(sf/2.0)]
    reduction = 1
    if reduce:
        if LPF <= samplefreq/2.0:
            reduction = int(samplefreq/LPF)
    if debugFlag is True:
        print "signalfilter: samplef: %f  wn: %f,  lpf: %f, NPoles: %d " % (
           sf, wn, flpf, NPole)
    filter_b,filter_a=spSignal.bessel(
            NPole,
            wn,
            btype = 'low',
            output = 'ba')
    if signal.ndim == 1:
        w=spSignal.lfilter(filter_b, filter_a, signal) # filter the incoming signal
        if reduction > 1:
            w = spSignal.resample(w, reduction)
        return(w)
    if signal.ndim == 2:
        sh = numpy.shape(signal)
        for i in range(0, numpy.shape(signal)[0]):
            w1 = spSignal.lfilter(filter_b, filter_a, signal[i,:])
            if reduction == 1:
                w1 = spSignal.resample(w1, reduction)
            if i == 0:
                w = numpy.empty((sh[0], numpy.shape(w1)[0]))
            w[i,:] = w1
        return w
    if signal.ndim == 3:
        sh = numpy.shape(signal)
        for i in range(0, numpy.shape(signal)[0]):
            for j in range(0, numpy.shape(signal)[1]):
                w1 = spSignal.lfilter(filter_b, filter_a, signal[i,j,:])
                if reduction == 1:
                    w1 = spSignal.resample(w1, reduction)
                if i == 0 and j == 0:
                    w = numpy.empty((sh[0], sh[1], numpy.shape(w1)[0]))
                w[i,j,:] = w1
        return(w)
    if signal.ndim > 3:
        print "Error: signal dimesions of > 3 are not supported (no filtering applied)"
        return signal


# do an eval on a long line (longer than 512 characters)
# assumes input is a dictionary (as a string) that is too long
# parses by breaking the string down and then reconstructing each element
#
def long_Eval(line):
    inpunct = False
    sp = ''
    u={}
    i = 0
    inpunct = 0
    colonFound = False
    inquote = False
    for c in line:
        if c is '{':
            continue
        if (c is ',' or c is '}') and colonFound and not inpunct and not inquote: # separator is ','
            r = eval('{%s}' % sp)
            u[r.keys()[0]] = r[r.keys()[0]]
            colonFound = False
            sp = ''
            continue
        sp = sp + c
        if c is ':':
            colonFound = True
            continue
        if c is '(' or c is '[' :
            inpunct += 1
            continue
        if c is ')' or c is ']':
            inpunct -= 1
            continue
        if c is "'" and inquote:
            inquote = False
            continue
        if c is "'" and not inquote:
            inquote is True
    return u


    # long_Eval()

    #
# routine to flatten an array/list.
#
def flatten(l, ltypes=(list, tuple)):
    i = 0
    while i < len(l):
        while isinstance(l[i], ltypes):
            if not l[i]:
                l.pop(i)
                if not len(l):
                    break
            else:
               l[i:i+1] = list(l[i])
        i += 1
    return l

# flatten()

def unique(seq, keepstr=True):
  t = type(seq)
  if t in (str, unicode):
    t = (list, ''.join)[bool(keepstr)]
  seen = []
  return t(c for c in seq if not (c in seen or seen.append(c)))


def findspikes(x, v, thresh, dt=1.0):
    """ findspikes identifies the times of action potential in the trace v, with the
    times in t. An action potential is simply timed at the first point that exceeds
    the threshold. """
    xt = numpy.array(x)
    v = numpy.array(v)
    st=numpy.array([])
    sp = numpy.where(v > thresh) # find points above threshold
    if sp == []:
        return(st)
    dsp = xt[sp] # get the spike "times"
    print dsp
    if dsp == []:
        return(st)
    if len(dsp) > 1:
        st = numpy.append(st, dsp[0]) # always get the first transition
    else:
        st = numpy.append(st, dsp)
    if len(dsp) > 1:
        sd = numpy.where(numpy.diff(dsp) > dt) # return only the first points of spikes
        if sd == []:
            return(st)
        else:
            st = numpy.append(st, sd)
            return(st)
    else:
        return(st)

# getSpikes returns a dictionary with keys that are record numbers, each with values
# that are the array of spike timesin the spike window.
# data is studied from the "axis", and only ONE block should be in the selection.
# thresh sets the spike threshold.

def getSpikes(x, y, axis, tpts, tdel=0, thresh=0, selection = None):
    if selection is None: # really means whatever is displayed/selected
        selected = numpy.arange(0, numpy.shape(y)[0]).astype(int).tolist()
    else:
        selected = selection
    splist = {}
    if y.ndim == 3:
        for r in selected:
            splist[r] = findspikes(x[tpts], y[r, axis, tpts], thresh)
    else:
        splist = findspikes(x[tpts], y[tpts], thresh)
    return(splist)

# return a measurement made on a block of traces
# within the window t0-t1, on the data "axis", and according to the selected mode

def measureTrace(x, y, t0 = 0, t1 = 10, thisaxis = 0, mode='mean', selection = None, threshold = 0):
    result = numpy.array([])
    if selection is None: # whooops
        return
    else:
        selected = selection
    if numpy.ndim(y) == 4:
        for i in range(0, len(y)):
            d = y[i][selected[i],thisaxis,:] # get data for this block
            for j in range(0, numpy.shape(d)[0]):
                if isinstance(threshold, int):
                    thr = threshold
                else:
                    thr = threshold[j]
                (m1, m2) = measure(mode, x[i], d[j,:], t0, t1, thresh= thr)
            result = numpy.append(result, m1)
    else:
        d = y[selected,thisaxis,:] # get data for this block
        for j in range(0, numpy.shape(d)[0]):
            if isinstance(threshold, int):
                thr = threshold
            else:
                thr = threshold[j]
            (m1, m2) = measure(mode, x, d[j,:], t0, t1, thresh= thr)
            result = numpy.append(result, m1)
    return(result)

def measure(mode, x, y, x0, x1, thresh = 0):
    """ return the a measure of y in the window x0 to x1
    """
    xm = ma.masked_outside(x, x0, x1)
    ym = ma.array(y, mask = ma.getmask(xm))
    if mode == 'mean':
        r1 = ma.mean(ym)
        r2 = ma.std(ym)
    if mode == 'max' or mode == 'maximum':
        r1 = ma.max(ym)
        r2 = 0
    if mode == 'min' or mode == 'minimum':
        r1 = ma.min(ym)
        r2 = 0
    if mode == 'median':
        r1 = ma.median(ym)
        r2 = 0
    if mode == 'p2p': # peak to peak
        r1 = ma.ptp(ym)
        r2 = 0
    if mode == 'std': # standard deviation
        r1 = ma.std(ym)
        r2 = 0
    if mode == 'var': # variance
        r1 = ma.var(ym)
        r2 = 0
    if mode == 'cumsum': # cumulative sum
        r1 = ma.cumsum(ym) # Note: returns an array
        r2 = 0
    if mode == 'anom': # anomalies = difference from averge
        r1 = ma.anom(ym) # returns an array
        r2 = 0
    if mode == 'sum':
        r1 = ma.sum(ym)
        r2 = 0
    if mode == 'area' or mode == 'charge':
        r1 = ma.sum(ym)/(ma.max(xm)-ma.min(xm))
        r2 = 0
    if mode == 'latency': # return first point that is > threshold
        sm = ma.nonzero(ym > thresh)
        r1 = -1  # use this to indicate no event detected
        r2 = 0
        if ma.count(sm) > 0:
            r1 = sm[0][0]
            r2 = len(sm[0])
    if mode == 'count':
        r1 = ma.count(ym)
        r2 = 0
    if mode == 'maxslope':
        return(0,0)
        slope = numpy.array([])
        win = ma.flatnotmasked_contiguous(ym)
        st = int(len(win)/20) # look over small ranges
        for k in win: # move through the slope measurementwindow
            tb = range(k-st, k+st) # get tb array
            newa = numpy.array(self.dat[i][j, thisaxis, tb])
            ppars = numpy.polyfit(x[tb], ym[tb], 1) # do a linear fit - smooths the slope measures
            slope = numpy.append(slope, ppars[0]) # keep track of max slope
        r1 = numpy.amax(slope)
        r2 = numpy.argmax(slope)
    return(r1, r2)

def mask(x, xm, x0, x1):
    if numpy.ndim(xm) != 1:
        print "utility: array to used to derive mask must be 1D"
        return(numpy.array([]))
    xmask = ma.masked_outside(xm, x0, x1)
    tmask =ma.getmask(xmask)
    if numpy.ndim(x) == 1:
        xnew = ma.array(x, mask=tmask)
        return(xnew.compressed())
    if numpy.ndim(x) == 2:
        for i in range(0, numpy.shape(x)[0]):
            xnew= ma.array(x[i,:], mask=tmask)
            xcmp = ma.compressed(xnew)
            if i == 0:
                print ma.shape(xcmp)[0]
                print numpy.shape(x)[0]
                xout = numpy.zeros(numpy.shape(x)[0], ma.shape(xcmp)[0])
            xout[i,:] = xcmp
        return(xout)
    else:
        print "Utility.Mask: dimensions of input arrays are not acceptable"
        return(numpy.array([]))

import os, sys, types, re, fnmatch, itertools

class ScriptError(Exception): pass

def ffind(path, shellglobs=None, namefs=None, relative=True):
    """
    Finds files in the directory tree starting at 'path' (filtered by
    Unix shell-style wildcards ('shellglobs') and/or the functions in
    the 'namefs' sequence).

    The parameters are as follows:

    - path: starting path of the directory tree to be searched
    - shellglobs: an optional sequence of Unix shell-style wildcards
      that are to be applied to the file *names* found
    - namefs: an optional sequence of functions to be applied to the
      file *paths* found
    - relative: a boolean flag that determines whether absolute or
      relative paths should be returned

    Please not that the shell wildcards work in a cumulative fashion
    i.e. each of them is applied to the full set of file *names* found.

    Conversely, all the functions in 'namefs'
        * only get to see the output of their respective predecessor
          function in the sequence (with the obvious exception of the
          first function)
        * are applied to the full file *path* (whereas the shell-style
          wildcards are only applied to the file *names*)

    Returns a sequence of paths for files found.
    """
    if not os.access(path, os.R_OK):
        raise ScriptError("cannot access path: '%s'" % path)

    fileList = [] # result list
    try:
        for dir, subdirs, files in os.walk(path):
            if shellglobs:
                matched = []
                for pattern in shellglobs:
                    filterf = lambda s: fnmatch.fnmatchcase(s, pattern)
                    matched.extend(filter(filterf, files))
                fileList.extend(['%s%s%s' % (dir, os.sep, f) for f in matched])
            else:
                fileList.extend(['%s%s%s' % (dir, os.sep, f) for f in files])
        if not relative: fileList = map(os.path.abspath, fileList)
        if namefs:
            for ff in namefs: fileList = filter(ff, fileList)
    except Exception, e: raise ScriptError(str(e))
    return(fileList)



def seqparse(sequence):
    """ parse the list of the format:
     12;23/10 etc... like nxtrec in datac
     now also parses matlab functions and array formats, using eval

     first arg is starting number for output array
     second arg is final number
     / indicates the skip arg type
     basic: /n means skip n : e.g., 1;10/2 = 1,3,5,7,9
     special: /##:r means randomize order (/##rn means use seed n for randomization)
     special: /##:l means spacing of elements is logarithmic
     special: /##:s means spacing is logarithmic, and order is randomized. (/##sn means use seed n for randomization)
     special: /:a## means alternate with a number
     multiple sequences are returned in a list... just like single sequences...

     3 ways for list to be structured:
     1. standard datac record parses. List is enclosed inbetween single quotes
     2. matlab : (array) operator expressions. [0:10:100], for example
     3. matlab functions (not enclosed in quotes). Each function generates a new list
     note that matlab functions and matrices are treated identically

     Updated 9/07/2000, 11/13/2000, 4/7/2004 (arbitrary matlab function argument with '=')
     converted to python 3/2/2009
     Paul B. Manis, Ph.D.
     pmanis@med.unc.edu
     """

    seq=[]
    target=[]
    sequence.replace(' ', '') # remove all spaces - nice to read, not needed to calculate
    sequence = str(sequence) #make sure we have a nice string
    (seq2, sep, remain) = sequence.partition('&') # find  and returnnested sequences
    while seq2 is not '':
        try:
            (oneseq, onetarget) = recparse(seq2)
            seq.append(oneseq)
            target.append(onetarget)
        except:
            pass
        (seq2, sep, remain) = remain.partition('&') # find  and returnnested sequences
    return (seq, target)


def recparse(cmdstr):
    """ function to parse basic word unit of the list - a;b/c or the like
    syntax is:
    [target:]a;b[/c][*n]
    where:
    target is a parameter target identification (if present)
    the target can be anything - a step, a duration, a level....
    it just needs to be in a form that will be interepreted by the PyStim
    sequencer.
    a, b and c are numbers
    n, if present *n implies a "mode"
    such as linear, log, randomized, etc.
    """

    recs=[]
    target=[]
    seed=0
    skip = 1.0
    (target, sep, rest) = cmdstr.partition(':') # get the target
    if rest is '':
        rest = target # no : found, so no target designated.
        target=''
    (sfn, sep, rest1) = rest.partition(';')
    (sln, sep, rest2) = rest1.partition('/')
    (sskip, sep, mo) = rest2.partition('*') # look for mode
    fn = float(sfn)
    ln = float(sln)
    skip = float(sskip)
    ln = ln + 0.01*skip
#    print "mo: %s" % (mo)
    if mo is '': # linear spacing; skip is size of step
        recs=eval('arange(%f,%f,%f)' % (fn, ln, skip))

    if mo.find('l') >= 0: # log spacing; skip is length of result
        recs=eval('logspace(log10(%f),log10(%f),%f)' % (fn, ln, skip))

    if mo.find('t') >= 0: # just repeat the first value
        recs = eval('%f*[1]' % (fn))

    if mo.find('n') >= 0: # use the number of steps, not the step size
        if skip is 1.0:
            sk = (ln - fn)
        else:
            sk = eval('(%f-%f)/(%f-1.0)' % (ln, fn, skip))
        recs=eval('arange(%f,%f,%f)' % (fn, ln, sk))

    if mo.find('r') >= 0: # randomize the result
        if recs is []:
            recs=eval('arange(%f,%f,%f)' % (fn, ln, skip))
        recs = sample(recs, len(recs))

    if mo.find('a') >= 0: # alternation - also test for a value after that
        (arg, sep, value) = mo.partition('a') # is there anything after the letter?
        if value is '':
            value = 0.0
        else:
            value = float(value)
        val = eval('%f' % (value))
        c = [val]*len(recs)*2 # double the length of the sequence
        c[0:len(c):2] = recs # fill the alternate positions with the sequence
        recs = c # copy back
    return((recs, target))


###############################################################################
#
# main entry
#

# provide test of routines.
if __name__ == "__main__":
    test = 'findspikes'

    if test == 'dictionary':
        d="{'CN_Dur': 100.0, 'PP_LP': 16000.0, 'ST_Dur': 50.0, 'Trials': 24.0, 'PP_HP': 8000.0, 'CN_Mode': 0, 'ITI_Var': 5.0, 'PP_GapFlag': False, 'PS_Dur': 50.0, 'ST_Level': 80.0, 'PP_Mode': 2, 'WavePlot': True, 'PP_Dur': 50.0, 'Analysis_LPF': 500.0, 'CN_Level': 70.0, 'NHabTrials': 2.0, 'PP_Notch_F2': 14000.0, 'PP_Notch_F1': 12000.0, 'StimEnable': True, 'PP_OffLevel': 0.0, 'Analysis_HPF': 75.0, 'CN_Var': 10.0, 'Analysis_Start': -100.0, 'ITI': 20.0, 'PP_Level': 90.0, 'Analysis_End': 100.0, 'PP_Freq': 4000.0, 'PP_MultiFreq': 'linspace(2.0,32.0,4.0)'} "
        di = long_Eval(d)
        print 'The dictionary is: ',
        print di

    if test == 'findspikes':
        t = numpy.arange(0, 100, 0.1)
        v = numpy.zeros_like(t)-60.0
        p = range(20, 900, 50)
        v[p] = 20.0
        sp = findspikes(t, v, 0.0)
        print sp
        print "now getSpikes"
        y=[]*5
        for j in range(0,1):
            d = numpy.zeros((5,1,len(v)))
            for k in range(0, 5):
                p = range(20*k, 500, 50 + int(50.0*(k/2.0)))
                vn = v.copy()
                vn[p] = 20.0
                d[k, 0, :] = numpy.array(vn) # load up the "spike" array
            y.append(d)
        tpts = range(0, len(t)) # numpy.arange(0, len(t)).astype(int).tolist()
        for k in range(0, len(y)):
            sp = getSpikes(t, y[k], 0, tpts, tdel=0, thresh=0, selection = None)
            print 'r: %d' % k, 'sp: ', sp
